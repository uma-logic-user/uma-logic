# scripts/archive_manager.py
# UMA-Logic PRO - éå»ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
# å®Œå…¨ç‰ˆï¼ˆFull Codeï¼‰- ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ï¼†ãƒšãƒ¼ã‚¹ãƒˆã§å‹•ä½œ

import json
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Set
import sys
import re

# --- å®šæ•° ---
DATA_DIR = Path("data")
ARCHIVE_DIR = DATA_DIR / "archive"
INDEX_FILE = ARCHIVE_DIR / "index.json"
RESULTS_PREFIX = "results_"
PREDICTIONS_PREFIX = "predictions_"


# --- ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚¯ãƒ©ã‚¹ ---

class ArchiveManager:
    """
    éå»ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
    data/archive/YYYY/MM/DD/ å½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†
    """

    def __init__(self):
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        ARCHIVE_DIR.mkdir(parents=True, exist_ok=True)
        self.index = self._load_index()

    def _load_index(self) -> Dict:
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿"""
        if INDEX_FILE.exists():
            try:
                with open(INDEX_FILE, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"[WARN] ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "updated_at": "",
            "total_dates": 0,
            "total_races": 0,
            "years": {},
            "venues": {},
            "date_index": {}
        }

    def _save_index(self):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜"""
        self.index["updated_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        with open(INDEX_FILE, 'w', encoding='utf-8') as f:
            json.dump(self.index, f, ensure_ascii=False, indent=2)

    def _get_archive_path(self, date_str: str) -> Path:
        """
        æ—¥ä»˜æ–‡å­—åˆ—ã‹ã‚‰ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‘ã‚¹ã‚’å–å¾—
        date_str: YYYYMMDDå½¢å¼
        returns: data/archive/YYYY/MM/DD/
        """
        year = date_str[:4]
        month = date_str[4:6]
        day = date_str[6:8]
        return ARCHIVE_DIR / year / month / day

    def _parse_date(self, date_str: str) -> Optional[datetime]:
        """æ—¥ä»˜æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹"""
        try:
            return datetime.strptime(date_str, "%Y%m%d")
        except ValueError:
            try:
                return datetime.strptime(date_str, "%Y-%m-%d")
            except ValueError:
                return None

    def archive_file(self, source_file: Path, date_str: str) -> bool:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•/ã‚³ãƒ”ãƒ¼
        ä¸€åº¦ä¿å­˜ã—ãŸãƒ‡ãƒ¼ã‚¿ã¯ä¸Šæ›¸ãã—ãªã„ï¼ˆä¸å¤‰ãƒ‡ãƒ¼ã‚¿åŒ–ï¼‰
        """
        if not source_file.exists():
            print(f"[WARN] ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {source_file}")
            return False

        archive_path = self._get_archive_path(date_str)
        archive_path.mkdir(parents=True, exist_ok=True)

        dest_file = archive_path / source_file.name

        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆä¸å¤‰ãƒ‡ãƒ¼ã‚¿åŒ–ï¼‰
        if dest_file.exists():
            print(f"[SKIP] æ—¢ã«ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ¸ˆã¿: {dest_file}")
            return True

        try:
            # ã‚³ãƒ”ãƒ¼ï¼ˆå…ƒãƒ•ã‚¡ã‚¤ãƒ«ã¯æ®‹ã™ï¼‰
            shutil.copy2(source_file, dest_file)
            print(f"[ARCHIVED] {source_file.name} â†’ {archive_path}")
            return True
        except Exception as e:
            print(f"[ERROR] ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å¤±æ•—: {e}")
            return False

    def archive_all_results(self) -> Dict:
        """
        data/ å†…ã®å…¨results_*.jsonã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
        """
        print("\n" + "=" * 60)
        print("ğŸ“š å…¨çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–")
        print("=" * 60)

        archived_count = 0
        skipped_count = 0
        failed_count = 0

        # results_*.json ã‚’æ¤œç´¢
        for result_file in DATA_DIR.glob(f"{RESULTS_PREFIX}*.json"):
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º
            match = re.search(r'results_(\d{8})', result_file.name)
            if not match:
                continue

            date_str = match.group(1)

            if self.archive_file(result_file, date_str):
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°
                self._update_index_for_file(result_file, date_str)
                archived_count += 1
            else:
                failed_count += 1

        # predictions_*.json ã‚‚åŒæ§˜ã«ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
        for pred_file in DATA_DIR.glob(f"{PREDICTIONS_PREFIX}*.json"):
            match = re.search(r'predictions_(\d{8})', pred_file.name)
            if not match:
                continue

            date_str = match.group(1)
            self.archive_file(pred_file, date_str)

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜
        self._save_index()

        print("\n" + "-" * 40)
        print(f"âœ… ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Œäº†")
        print(f"   æ–°è¦: {archived_count}ä»¶")
        print(f"   ã‚¹ã‚­ãƒƒãƒ—: {skipped_count}ä»¶")
        print(f"   å¤±æ•—: {failed_count}ä»¶")

        return {
            "archived": archived_count,
            "skipped": skipped_count,
            "failed": failed_count
        }

    def _update_index_for_file(self, file_path: Path, date_str: str):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¿½åŠ """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except Exception as e:
            print(f"[WARN] ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return

        year = date_str[:4]
        month = date_str[4:6]
        day = date_str[6:8]
        date_key = f"{year}-{month}-{day}"

        # å¹´åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        if year not in self.index["years"]:
            self.index["years"][year] = {
                "months": {},
                "total_dates": 0,
                "total_races": 0
            }

        # æœˆåˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        if month not in self.index["years"][year]["months"]:
            self.index["years"][year]["months"][month] = {
                "days": [],
                "total_races": 0
            }

        if day not in self.index["years"][year]["months"][month]["days"]:
            self.index["years"][year]["months"][month]["days"].append(day)
            self.index["years"][year]["total_dates"] += 1

        # ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’æŠ½å‡º
        races = data.get("races", [])
        race_count = len(races)

        self.index["years"][year]["months"][month]["total_races"] += race_count
        self.index["years"][year]["total_races"] += race_count

        # æ—¥ä»˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        if date_key not in self.index["date_index"]:
            self.index["date_index"][date_key] = {
                "file_path": str(self._get_archive_path(date_str) / file_path.name),
                "race_count": race_count,
                "venues": []
            }

        # ç«¶é¦¬å ´æƒ…å ±ã‚’æŠ½å‡º
        venues = set()
        for race in races:
            venue = race.get("venue", "")
            if venue:
                venues.add(venue)

                # ç«¶é¦¬å ´åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                if venue not in self.index["venues"]:
                    self.index["venues"][venue] = {
                        "dates": [],
                        "total_races": 0
                    }
                if date_key not in self.index["venues"][venue]["dates"]:
                    self.index["venues"][venue]["dates"].append(date_key)
                self.index["venues"][venue]["total_races"] += 1

        self.index["date_index"][date_key]["venues"] = list(venues)

        # ç·è¨ˆã‚’æ›´æ–°
        self.index["total_dates"] = len(self.index["date_index"])
        self.index["total_races"] = sum(
            self.index["years"][y]["total_races"]
            for y in self.index["years"]
        )

    def rebuild_index(self) -> Dict:
        """
        ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å®Œå…¨ã«å†æ§‹ç¯‰
        ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³
        """
        print("\n" + "=" * 60)
        print("ğŸ”„ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰")
        print("=" * 60)

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
        self.index = {
            "updated_at": "",
            "total_dates": 0,
            "total_races": 0,
            "years": {},
            "venues": {},
            "date_index": {}
        }

        file_count = 0

        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å†å¸°çš„ã«ã‚¹ã‚­ãƒ£ãƒ³
        for year_dir in sorted(ARCHIVE_DIR.iterdir()):
            if not year_dir.is_dir() or not year_dir.name.isdigit():
                continue

            year = year_dir.name
            print(f"\n[INFO] {year}å¹´ã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­...")

            for month_dir in sorted(year_dir.iterdir()):
                if not month_dir.is_dir() or not month_dir.name.isdigit():
                    continue

                month = month_dir.name

                for day_dir in sorted(month_dir.iterdir()):
                    if not day_dir.is_dir() or not day_dir.name.isdigit():
                        continue

                    day = day_dir.name
                    date_str = f"{year}{month}{day}"

                    # results_*.json ã‚’æ¤œç´¢
                    for result_file in day_dir.glob(f"{RESULTS_PREFIX}*.json"):
                        self._update_index_for_file(result_file, date_str)
                        file_count += 1

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜
        self._save_index()

        print("\n" + "-" * 40)
        print(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰å®Œäº†")
        print(f"   ã‚¹ã‚­ãƒ£ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«: {file_count}ä»¶")
        print(f"   ç™»éŒ²æ—¥æ•°: {self.index['total_dates']}æ—¥")
        print(f"   ç™»éŒ²ãƒ¬ãƒ¼ã‚¹: {self.index['total_races']}ä»¶")

        return {
            "files_scanned": file_count,
            "total_dates": self.index["total_dates"],
            "total_races": self.index["total_races"]
        }

    def get_available_years(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªå¹´ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        return sorted(self.index.get("years", {}).keys(), reverse=True)

    def get_available_months(self, year: str) -> List[str]:
        """æŒ‡å®šå¹´ã®åˆ©ç”¨å¯èƒ½ãªæœˆã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        year_data = self.index.get("years", {}).get(year, {})
        return sorted(year_data.get("months", {}).keys())

    def get_available_days(self, year: str, month: str) -> List[str]:
        """æŒ‡å®šå¹´æœˆã®åˆ©ç”¨å¯èƒ½ãªæ—¥ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        year_data = self.index.get("years", {}).get(year, {})
        month_data = year_data.get("months", {}).get(month, {})
        return sorted(month_data.get("days", []))

    def get_available_venues(self, date_str: str) -> List[str]:
        """æŒ‡å®šæ—¥ã®åˆ©ç”¨å¯èƒ½ãªç«¶é¦¬å ´ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        # date_str: YYYYMMDD ã¾ãŸã¯ YYYY-MM-DD
        if "-" in date_str:
            date_key = date_str
        else:
            date_key = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"

        date_data = self.index.get("date_index", {}).get(date_key, {})
        return date_data.get("venues", [])

    def get_races_by_date(self, date_str: str) -> Optional[Dict]:
        """
        æŒ‡å®šæ—¥ã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‹ã‚‰é«˜é€Ÿã«èª­ã¿è¾¼ã¿
        """
        # date_str: YYYYMMDDå½¢å¼ã«æ­£è¦åŒ–
        if "-" in date_str:
            date_str = date_str.replace("-", "")

        archive_path = self._get_archive_path(date_str)
        result_file = archive_path / f"{RESULTS_PREFIX}{date_str}.json"

        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«ãªã„å ´åˆã¯data/ã‹ã‚‰èª­ã¿è¾¼ã¿
        if not result_file.exists():
            result_file = DATA_DIR / f"{RESULTS_PREFIX}{date_str}.json"

        if not result_file.exists():
            return None

        try:
            with open(result_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"[ERROR] ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def get_races_by_date_and_venue(self, date_str: str, venue: str) -> List[Dict]:
        """
        æŒ‡å®šæ—¥ãƒ»æŒ‡å®šç«¶é¦¬å ´ã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        """
        data = self.get_races_by_date(date_str)
        if not data:
            return []

        races = data.get("races", [])
        return [r for r in races if r.get("venue", "") == venue]

    def get_statistics(self) -> Dict:
        """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        stats = {
            "updated_at": self.index.get("updated_at", ""),
            "total_dates": self.index.get("total_dates", 0),
            "total_races": self.index.get("total_races", 0),
            "years": {},
            "venues": {}
        }

        # å¹´åˆ¥çµ±è¨ˆ
        for year, year_data in self.index.get("years", {}).items():
            stats["years"][year] = {
                "total_dates": year_data.get("total_dates", 0),
                "total_races": year_data.get("total_races", 0),
                "months": list(year_data.get("months", {}).keys())
            }

        # ç«¶é¦¬å ´åˆ¥çµ±è¨ˆ
        for venue, venue_data in self.index.get("venues", {}).items():
            stats["venues"][venue] = {
                "total_dates": len(venue_data.get("dates", [])),
                "total_races": venue_data.get("total_races", 0)
            }

        return stats

    def archive_today_results(self) -> bool:
        """æœ¬æ—¥ã®çµæœã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–"""
        today_str = datetime.now().strftime("%Y%m%d")
        result_file = DATA_DIR / f"{RESULTS_PREFIX}{today_str}.json"

        if result_file.exists():
            success = self.archive_file(result_file, today_str)
            if success:
                self._update_index_for_file(result_file, today_str)
                self._save_index()
            return success
        else:
            print(f"[INFO] æœ¬æ—¥ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“: {result_file}")
            return False

    def check_archived(self, date_str: str) -> bool:
        """æŒ‡å®šæ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯"""
        archive_path = self._get_archive_path(date_str)
        result_file = archive_path / f"{RESULTS_PREFIX}{date_str}.json"
        return result_file.exists()


# --- UIç”¨é«˜é€Ÿæ¤œç´¢ã‚¯ãƒ©ã‚¹ ---

class ArchiveSearcher:
    """
    UIã‹ã‚‰ã®é«˜é€Ÿæ¤œç´¢ç”¨ã‚¯ãƒ©ã‚¹
    ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ã—ã¦é«˜é€Ÿã«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    """

    def __init__(self):
        self.manager = ArchiveManager()

    def get_hierarchical_data(self) -> Dict:
        """
        éšå±¤å‹æ¤œç´¢ç”¨ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’å–å¾—
        å¹´ > æœˆ > æ—¥ > ç«¶é¦¬å ´ ã®éšå±¤
        """
        result = {
            "years": []
        }

        for year in self.manager.get_available_years():
            year_data = {
                "year": year,
                "months": []
            }

            for month in self.manager.get_available_months(year):
                month_data = {
                    "month": month,
                    "days": []
                }

                for day in self.manager.get_available_days(year, month):
                    date_str = f"{year}{month}{day}"
                    venues = self.manager.get_available_venues(date_str)

                    day_data = {
                        "day": day,
                        "date_str": date_str,
                        "venues": venues
                    }
                    month_data["days"].append(day_data)

                year_data["months"].append(month_data)

            result["years"].append(year_data)

        return result

    def search_races(
        self,
        year: str = None,
        month: str = None,
        day: str = None,
        venue: str = None
    ) -> List[Dict]:
        """
        æ¡ä»¶ã«åŸºã¥ã„ã¦ãƒ¬ãƒ¼ã‚¹ã‚’æ¤œç´¢
        """
        results = []

        # æ—¥ä»˜ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
        if year and month and day:
            date_str = f"{year}{month}{day}"

            if venue:
                races = self.manager.get_races_by_date_and_venue(date_str, venue)
            else:
                data = self.manager.get_races_by_date(date_str)
                races = data.get("races", []) if data else []

            return races

        # å¹´æœˆã®ã¿æŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
        if year and month:
            days = self.manager.get_available_days(year, month)
            for d in days:
                date_str = f"{year}{month}{d}"
                data = self.manager.get_races_by_date(date_str)
                if data:
                    for race in data.get("races", []):
                        if venue is None or race.get("venue") == venue:
                            race["date"] = date_str
                            results.append(race)
            return results

        # å¹´ã®ã¿æŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
        if year:
            months = self.manager.get_available_months(year)
            for m in months:
                days = self.manager.get_available_days(year, m)
                for d in days:
                    date_str = f"{year}{m}{d}"
                    data = self.manager.get_races_by_date(date_str)
                    if data:
                        for race in data.get("races", []):
                            if venue is None or race.get("venue") == venue:
                                race["date"] = date_str
                                results.append(race)
            return results

        return results


# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---

def main():
    print("=" * 60)
    print("ğŸ“š UMA-Logic PRO - ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼")
    print("=" * 60)

    manager = ArchiveManager()

    if len(sys.argv) > 1:
        command = sys.argv[1]

        if command == "--archive-all":
            # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
            result = manager.archive_all_results()
            print(f"\nçµæœ: {result}")

        elif command == "--rebuild-index":
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰
            result = manager.rebuild_index()
            print(f"\nçµæœ: {result}")

        elif command == "--stats":
            # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
            stats = manager.get_statistics()
            print("\nğŸ“Š ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–çµ±è¨ˆ")
            print("-" * 40)
            print(f"æœ€çµ‚æ›´æ–°: {stats['updated_at']}")
            print(f"ç·æ—¥æ•°: {stats['total_dates']}æ—¥")
            print(f"ç·ãƒ¬ãƒ¼ã‚¹: {stats['total_races']}ä»¶")

            print("\nğŸ“… å¹´åˆ¥çµ±è¨ˆ:")
            for year, data in sorted(stats["years"].items(), reverse=True):
                print(f"  {year}å¹´: {data['total_dates']}æ—¥ / {data['total_races']}ãƒ¬ãƒ¼ã‚¹")
                print(f"    æœˆ: {', '.join(data['months'])}")

            print("\nğŸŸï¸ ç«¶é¦¬å ´åˆ¥çµ±è¨ˆ:")
            for venue, data in sorted(stats["venues"].items(), key=lambda x: x[1]["total_races"], reverse=True):
                print(f"  {venue}: {data['total_dates']}æ—¥ / {data['total_races']}ãƒ¬ãƒ¼ã‚¹")

        elif command == "--archive-date":
            # æŒ‡å®šæ—¥ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
            if len(sys.argv) > 2:
                date_str = sys.argv[2]
                result_file = DATA_DIR / f"{RESULTS_PREFIX}{date_str}.json"
                if result_file.exists():
                    manager.archive_file(result_file, date_str)
                    manager._update_index_for_file(result_file, date_str)
                    manager._save_index()
                else:
                    print(f"[ERROR] ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {result_file}")
            else:
                print("[ERROR] æ—¥ä»˜ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ (ä¾‹: --archive-date 20240106)")

        elif command == "--search":
            # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
            searcher = ArchiveSearcher()
            hierarchical = searcher.get_hierarchical_data()
            print("\nğŸ“‚ éšå±¤å‹ãƒ‡ãƒ¼ã‚¿æ§‹é€ :")
            for year_data in hierarchical["years"][:2]:  # æœ€æ–°2å¹´ã®ã¿è¡¨ç¤º
                print(f"\n  {year_data['year']}å¹´:")
                for month_data in year_data["months"][:3]:  # æœ€æ–°3ãƒ¶æœˆã®ã¿è¡¨ç¤º
                    print(f"    {month_data['month']}æœˆ: {len(month_data['days'])}æ—¥")

        elif command == "--check":
            # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
            if len(sys.argv) > 2:
                date_str = sys.argv[2]
                if manager.check_archived(date_str):
                    print(f"âœ… {date_str} ã¯ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ¸ˆã¿ã§ã™")
                else:
                    print(f"âŒ {date_str} ã¯ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            else:
                print("[ERROR] æ—¥ä»˜ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ (ä¾‹: --check 20240106)")

        else:
            print(f"[ERROR] ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {command}")
            print("\nä½¿ç”¨æ–¹æ³•:")
            print("  --archive-all      : å…¨çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–")
            print("  --rebuild-index    : ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰")
            print("  --stats            : çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º")
            print("  --archive-date DATE: æŒ‡å®šæ—¥ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ– (ä¾‹: 20240106)")
            print("  --search           : æ¤œç´¢ãƒ†ã‚¹ãƒˆ")
            print("  --check DATE       : ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–çŠ¶æ…‹ã‚’ç¢ºèª")

    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ¬æ—¥ã®çµæœã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
        print("\n[INFO] æœ¬æ—¥ã®çµæœã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã—ã¾ã™...")
        manager.archive_today_results()

    print("\nâœ… å‡¦ç†å®Œäº†")


if __name__ == "__main__":
    main()
