# scripts/scraper_realtime.py
# UMA-Logic PRO - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ï¼†ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼æ¢çŸ¥æ©Ÿ
# å®Œå…¨ç‰ˆï¼ˆFull Codeï¼‰- ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ï¼†ãƒšãƒ¼ã‚¹ãƒˆã§å‹•ä½œ

import requests
from bs4 import BeautifulSoup
import json
import time
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field, asdict
import math
import sys

# --- å®šæ•° ---
DATA_DIR = Path("data")
ODDS_DIR = DATA_DIR / "odds"
ALERTS_FILE = DATA_DIR / "insider_alerts.json"
REALTIME_STATE_FILE = DATA_DIR / "realtime_state.json"

MAX_RETRIES = 3
REQUEST_TIMEOUT = 15
REQUEST_INTERVAL = 1.0

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "ja,en-US;q=0.7,en;q=0.3",
}

# ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼æ¤œçŸ¥é–¾å€¤
INSIDER_THRESHOLDS = {
    "odds_drop_rate": 0.20,
    "odds_drop_rate_fast": 0.15,
    "time_window_minutes": 30,
    "min_odds_for_alert": 3.0,
    "max_odds_for_alert": 50.0,
}


# --- ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ ---

@dataclass
class OddsSnapshot:
    """ã‚ªãƒƒã‚ºã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ"""
    timestamp: str
    race_id: str
    race_num: int
    venue: str
    horses: List[Dict] = field(default_factory=list)


@dataclass
class InsiderAlert:
    """ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼ã‚¢ãƒ©ãƒ¼ãƒˆ"""
    alert_id: str
    race_id: str
    race_num: int
    venue: str
    umaban: int
    horse_name: str
    odds_before: float
    odds_after: float
    drop_rate: float
    time_span_minutes: int
    detected_at: str
    confidence: float
    expected_value_boost: float
    aggressive_mode: bool
    status: str = "active"

    def to_dict(self) -> Dict:
        return asdict(self)


# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---

def get_jst_now() -> datetime:
    """æ—¥æœ¬æ™‚é–“ã®ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—"""
    try:
        import pytz
        jst = pytz.timezone('Asia/Tokyo')
        return datetime.now(jst)
    except ImportError:
        return datetime.now() + timedelta(hours=9)


def fetch_with_retry(url: str, encoding: str = 'euc-jp') -> Optional[str]:
    """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    for attempt in range(MAX_RETRIES):
        try:
            response = requests.get(url, headers=HEADERS, timeout=REQUEST_TIMEOUT)
            response.encoding = encoding
            if response.status_code == 200:
                return response.text
        except Exception as e:
            print(f"[WARN] ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ (attempt {attempt + 1}): {e}")
            time.sleep(2)
    return None


# --- ã‚ªãƒƒã‚ºå–å¾—ã‚¯ãƒ©ã‚¹ ---

class OddsScraper:
    """netkeibaã‹ã‚‰ã‚ªãƒƒã‚ºã‚’å–å¾—"""

    def __init__(self):
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        ODDS_DIR.mkdir(parents=True, exist_ok=True)

    def get_today_race_ids(self) -> List[Dict]:
        """æœ¬æ—¥ã®ãƒ¬ãƒ¼ã‚¹IDä¸€è¦§ã‚’å–å¾—"""
        now = get_jst_now()
        date_str = now.strftime("%Y%m%d")

        url = f"https://race.netkeiba.com/top/race_list.html?kaisai_date={date_str}"
        html = fetch_with_retry(url, encoding='utf-8')

        if not html:
            print("[WARN] ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return []

        soup = BeautifulSoup(html, 'lxml')
        races = []

        # ãƒ¬ãƒ¼ã‚¹ãƒªãƒ³ã‚¯ã‚’æ¢ã™
        for link in soup.find_all('a', href=re.compile(r'/race/\d+')):
            href = link.get('href', '')
            match = re.search(r'/race/(\d+)', href)
            if match:
                race_id = match.group(1)

                # ç«¶é¦¬å ´ã¨ãƒ¬ãƒ¼ã‚¹ç•ªå·ã‚’æŠ½å‡º
                venue = ""
                race_num = 0

                # è¦ªè¦ç´ ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
                text = link.get_text(strip=True)
                num_match = re.search(r'(\d+)R', text)
                if num_match:
                    race_num = int(num_match.group(1))

                # ç«¶é¦¬å ´åã‚’æ¢ã™
                parent = link.find_parent('div', class_='RaceList_DataItem')
                if parent:
                    venue_elem = parent.find_previous('span', class_='RaceList_DataTitle')
                    if venue_elem:
                        venue = venue_elem.get_text(strip=True)

                if race_id not in [r['race_id'] for r in races]:
                    races.append({
                        'race_id': race_id,
                        'race_num': race_num,
                        'venue': venue
                    })

        print(f"[INFO] {len(races)}ãƒ¬ãƒ¼ã‚¹ã‚’æ¤œå‡º")
        return races

    def fetch_odds(self, race_id: str) -> Optional[Dict]:
        """æŒ‡å®šãƒ¬ãƒ¼ã‚¹ã®ã‚ªãƒƒã‚ºã‚’å–å¾—"""
        url = f"https://race.netkeiba.com/odds/index.html?race_id={race_id}&type=b1"
        html = fetch_with_retry(url, encoding='utf-8')

        if not html:
            return None

        soup = BeautifulSoup(html, 'lxml')
        horses = []

        # ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
        odds_table = soup.find('table', class_='RaceOdds_HorseList_Table')
        if not odds_table:
            # åˆ¥ã®å½¢å¼ã‚’è©¦ã™
            odds_table = soup.find('table', id='odds_tan_block')

        if odds_table:
            for row in odds_table.find_all('tr'):
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 3:
                    try:
                        # é¦¬ç•ª
                        umaban_cell = cells[0]
                        umaban_text = umaban_cell.get_text(strip=True)
                        if not umaban_text.isdigit():
                            continue
                        umaban = int(umaban_text)

                        # é¦¬å
                        horse_name = ""
                        name_cell = cells[1] if len(cells) > 1 else None
                        if name_cell:
                            horse_name = name_cell.get_text(strip=True)

                        # ã‚ªãƒƒã‚º
                        odds = 0.0
                        for cell in cells:
                            text = cell.get_text(strip=True)
                            odds_match = re.search(r'(\d+\.?\d*)', text)
                            if odds_match and '.' in text:
                                odds = float(odds_match.group(1))
                                break

                        if umaban > 0 and odds > 0:
                            horses.append({
                                'umaban': umaban,
                                'horse_name': horse_name,
                                'odds': odds
                            })
                    except Exception:
                        continue

        # åˆ¥ã®æ–¹æ³•ã§ã‚ªãƒƒã‚ºã‚’å–å¾—
        if not horses:
            odds_spans = soup.find_all('span', class_='Odds')
            for i, span in enumerate(odds_spans):
                try:
                    odds_text = span.get_text(strip=True)
                    odds = float(odds_text)
                    horses.append({
                        'umaban': i + 1,
                        'horse_name': f"é¦¬{i+1}",
                        'odds': odds
                    })
                except Exception:
                    continue

        if horses:
            return {
                'race_id': race_id,
                'timestamp': get_jst_now().strftime("%Y-%m-%d %H:%M:%S"),
                'horses': horses
            }

        return None

    def fetch_all_odds(self) -> List[Dict]:
        """å…¨ãƒ¬ãƒ¼ã‚¹ã®ã‚ªãƒƒã‚ºã‚’å–å¾—"""
        races = self.get_today_race_ids()
        all_odds = []

        for race in races:
            race_id = race['race_id']
            print(f"  å–å¾—ä¸­: {race_id}")

            odds_data = self.fetch_odds(race_id)
            if odds_data:
                odds_data['venue'] = race.get('venue', '')
                odds_data['race_num'] = race.get('race_num', 0)
                all_odds.append(odds_data)

            time.sleep(REQUEST_INTERVAL)

        return all_odds

    def save_odds_snapshot(self, odds_list: List[Dict]) -> Path:
        """ã‚ªãƒƒã‚ºã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜"""
        now = get_jst_now()
        filename = f"odds_{now.strftime('%Y%m%d_%H%M%S')}.json"
        filepath = ODDS_DIR / filename

        data = {
            'timestamp': now.strftime("%Y-%m-%d %H:%M:%S"),
            'races': odds_list
        }

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"[SAVED] {filepath}")
        return filepath


# --- ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼æ¤œçŸ¥ã‚¯ãƒ©ã‚¹ ---

class InsiderDetector:
    """ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼ï¼ˆæ€¥æ¿€ãªã‚ªãƒƒã‚ºå¤‰å‹•ï¼‰ã‚’æ¤œçŸ¥"""

    def __init__(self):
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        self.alerts = self._load_alerts()
        self.state = self._load_state()

    def _load_alerts(self) -> Dict:
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿"""
        if ALERTS_FILE.exists():
            try:
                with open(ALERTS_FILE, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                pass
        return {"alerts": [], "updated_at": ""}

    def _save_alerts(self):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ä¿å­˜"""
        self.alerts["updated_at"] = get_jst_now().strftime("%Y-%m-%d %H:%M:%S")
        with open(ALERTS_FILE, 'w', encoding='utf-8') as f:
            json.dump(self.alerts, f, ensure_ascii=False, indent=2)

    def _load_state(self) -> Dict:
        """çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã¿"""
        if REALTIME_STATE_FILE.exists():
            try:
                with open(REALTIME_STATE_FILE, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                pass
        return {"last_odds": {}, "updated_at": ""}

    def _save_state(self):
        """çŠ¶æ…‹ã‚’ä¿å­˜"""
        self.state["updated_at"] = get_jst_now().strftime("%Y-%m-%d %H:%M:%S")
        with open(REALTIME_STATE_FILE, 'w', encoding='utf-8') as f:
            json.dump(self.state, f, ensure_ascii=False, indent=2)

    def get_previous_odds(self) -> List[Dict]:
        """ç›´å‰ã®ã‚ªãƒƒã‚ºã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—"""
        odds_files = sorted(ODDS_DIR.glob("odds_*.json"), reverse=True)

        if len(odds_files) < 2:
            return []

        # 2ç•ªç›®ã«æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå‰å›ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼‰
        prev_file = odds_files[1]

        try:
            with open(prev_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('races', [])
        except Exception:
            return []

    def detect_insider(self, current_odds: List[Dict], previous_odds: List[Dict]) -> List[InsiderAlert]:
        """ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼ï¼ˆæ€¥æ¿€ãªã‚ªãƒƒã‚ºå¤‰å‹•ï¼‰ã‚’æ¤œçŸ¥"""
        alerts = []
        now = get_jst_now()

        # å‰å›ã®ã‚ªãƒƒã‚ºã‚’race_id + umabanã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
        prev_index = {}
        for race in previous_odds:
            race_id = race.get('race_id', '')
            for horse in race.get('horses', []):
                key = f"{race_id}_{horse.get('umaban', 0)}"
                prev_index[key] = {
                    'odds': horse.get('odds', 0),
                    'horse_name': horse.get('horse_name', ''),
                    'venue': race.get('venue', ''),
                    'race_num': race.get('race_num', 0)
                }

        # ç¾åœ¨ã®ã‚ªãƒƒã‚ºã¨æ¯”è¼ƒ
        for race in current_odds:
            race_id = race.get('race_id', '')
            venue = race.get('venue', '')
            race_num = race.get('race_num', 0)

            for horse in race.get('horses', []):
                umaban = horse.get('umaban', 0)
                current_odds_val = horse.get('odds', 0)
                horse_name = horse.get('horse_name', '')

                key = f"{race_id}_{umaban}"

                if key not in prev_index:
                    continue

                prev_data = prev_index[key]
                prev_odds_val = prev_data['odds']

                # ã‚ªãƒƒã‚ºãŒæœ‰åŠ¹ç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
                if current_odds_val < INSIDER_THRESHOLDS['min_odds_for_alert']:
                    continue
                if current_odds_val > INSIDER_THRESHOLDS['max_odds_for_alert']:
                    continue

                # ã‚ªãƒƒã‚ºä½ä¸‹ç‡ã‚’è¨ˆç®—
                if prev_odds_val > 0 and current_odds_val > 0:
                    drop_rate = (prev_odds_val - current_odds_val) / prev_odds_val

                    # 20%ä»¥ä¸Šã®æ€¥è½ã‚’æ¤œçŸ¥
                    if drop_rate >= INSIDER_THRESHOLDS['odds_drop_rate']:
                        # ä¿¡é ¼åº¦ã‚’è¨ˆç®—ï¼ˆä½ä¸‹ç‡ãŒå¤§ãã„ã»ã©é«˜ã„ï¼‰
                        confidence = min(1.0, drop_rate / 0.4)

                        # æœŸå¾…å€¤ãƒ–ãƒ¼ã‚¹ãƒˆä¿‚æ•°ã‚’è¨ˆç®—
                        ev_boost = 1.0 + (drop_rate * 0.5)
                        ev_boost = min(1.35, ev_boost)

                        # Aggressiveãƒ¢ãƒ¼ãƒ‰ã‚’åˆ¤å®šï¼ˆ30%ä»¥ä¸Šã®æ€¥è½ï¼‰
                        aggressive_mode = drop_rate >= 0.30

                        alert = InsiderAlert(
                            alert_id=f"{race_id}_{umaban}_{now.strftime('%H%M%S')}",
                            race_id=race_id,
                            race_num=race_num,
                            venue=venue or prev_data.get('venue', ''),
                            umaban=umaban,
                            horse_name=horse_name or prev_data.get('horse_name', ''),
                            odds_before=prev_odds_val,
                            odds_after=current_odds_val,
                            drop_rate=drop_rate,
                            time_span_minutes=10,
                            detected_at=now.strftime("%Y-%m-%d %H:%M:%S"),
                            confidence=confidence,
                            expected_value_boost=ev_boost,
                            aggressive_mode=aggressive_mode,
                            status="active"
                        )

                        alerts.append(alert)

                        print(f"\nğŸš¨ ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼æ¤œçŸ¥!")
                        print(f"   {venue} {race_num}R - {horse_name} (é¦¬ç•ª{umaban})")
                        print(f"   ã‚ªãƒƒã‚º: {prev_odds_val:.1f} â†’ {current_odds_val:.1f} ({drop_rate*100:.1f}%ä½ä¸‹)")
                        print(f"   ä¿¡é ¼åº¦: {confidence*100:.0f}%")
                        print(f"   æœŸå¾…å€¤ãƒ–ãƒ¼ã‚¹ãƒˆ: {ev_boost:.2f}x")
                        if aggressive_mode:
                            print(f"   âš¡ Aggressiveãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹")

        return alerts

    def update_alerts(self, new_alerts: List[InsiderAlert]):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚’æ›´æ–°"""
        # æ—¢å­˜ã®ã‚¢ãƒ©ãƒ¼ãƒˆã‚’å¤ã„ã‚‚ã®ã¯éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«
        now = get_jst_now()
        for alert in self.alerts.get("alerts", []):
            detected_at = datetime.strptime(alert["detected_at"], "%Y-%m-%d %H:%M:%S")
            if (now - detected_at).total_seconds() > 3600:  # 1æ™‚é–“ä»¥ä¸Šå‰
                alert["status"] = "expired"

        # æ–°ã—ã„ã‚¢ãƒ©ãƒ¼ãƒˆã‚’è¿½åŠ 
        for alert in new_alerts:
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            existing_ids = [a["alert_id"] for a in self.alerts.get("alerts", [])]
            if alert.alert_id not in existing_ids:
                self.alerts["alerts"].append(alert.to_dict())

        # ä¿å­˜
        self._save_alerts()

    def run_detection(self, current_odds: List[Dict]) -> List[InsiderAlert]:
        """æ¤œçŸ¥ã‚’å®Ÿè¡Œ"""
        previous_odds = self.get_previous_odds()

        if not previous_odds:
            print("[INFO] å‰å›ã®ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ¬¡å›ã‹ã‚‰æ¤œçŸ¥ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            return []

        alerts = self.detect_insider(current_odds, previous_odds)

        if alerts:
            self.update_alerts(alerts)
            print(f"\n[INFO] {len(alerts)}ä»¶ã®ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼ã‚¢ãƒ©ãƒ¼ãƒˆã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
        else:
            print("\n[INFO] ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

        return alerts


# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---

def main():
    print("=" * 60)
    print("ğŸ’¹ UMA-Logic PRO - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ªãƒƒã‚ºï¼†ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼æ¢çŸ¥")
    print("=" * 60)

    scraper = OddsScraper()
    detector = InsiderDetector()

    if len(sys.argv) > 1:
        command = sys.argv[1]

        if command == "--fetch":
            # ã‚ªãƒƒã‚ºå–å¾—ã®ã¿
            print("\n[INFO] ã‚ªãƒƒã‚ºã‚’å–å¾—ä¸­...")
            odds_list = scraper.fetch_all_odds()
            if odds_list:
                scraper.save_odds_snapshot(odds_list)
                print(f"\nâœ… {len(odds_list)}ãƒ¬ãƒ¼ã‚¹ã®ã‚ªãƒƒã‚ºã‚’å–å¾—ã—ã¾ã—ãŸ")
            else:
                print("\n[WARN] ã‚ªãƒƒã‚ºã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

        elif command == "--detect":
            # æ¤œçŸ¥ã®ã¿ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
            print("\n[INFO] ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼æ¤œçŸ¥ã‚’å®Ÿè¡Œä¸­...")
            odds_files = sorted(ODDS_DIR.glob("odds_*.json"), reverse=True)
            if odds_files:
                with open(odds_files[0], 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    current_odds = data.get('races', [])
                detector.run_detection(current_odds)
            else:
                print("[WARN] ã‚ªãƒƒã‚ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

        elif command == "--status":
            # ç¾åœ¨ã®çŠ¶æ…‹ã‚’è¡¨ç¤º
            print("\nğŸ“Š ç¾åœ¨ã®çŠ¶æ…‹")
            print("-" * 40)

            alerts = detector.alerts.get("alerts", [])
            active_alerts = [a for a in alerts if a.get("status") == "active"]

            print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆ: {len(active_alerts)}ä»¶")
            print(f"ç·ã‚¢ãƒ©ãƒ¼ãƒˆæ•°: {len(alerts)}ä»¶")
            print(f"æœ€çµ‚æ›´æ–°: {detector.alerts.get('updated_at', 'N/A')}")

            if active_alerts:
                print("\nğŸš¨ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆ:")
                for alert in active_alerts[:5]:
                    print(f"  - {alert.get('venue', '')} {alert.get('race_num', '')}R")
                    print(f"    {alert.get('horse_name', '')} (é¦¬ç•ª{alert.get('umaban', '')})")
                    print(f"    ã‚ªãƒƒã‚º: {alert.get('odds_before', 0):.1f} â†’ {alert.get('odds_after', 0):.1f}")

        elif command == "--clear":
            # ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢
            detector.alerts = {"alerts": [], "updated_at": ""}
            detector._save_alerts()
            print("âœ… ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")

        else:
            print(f"[ERROR] ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {command}")
            print("\nä½¿ç”¨æ–¹æ³•:")
            print("  --fetch   : ã‚ªãƒƒã‚ºã‚’å–å¾—")
            print("  --detect  : ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼æ¤œçŸ¥ã‚’å®Ÿè¡Œ")
            print("  --status  : ç¾åœ¨ã®çŠ¶æ…‹ã‚’è¡¨ç¤º")
            print("  --clear   : ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢")
            print("  (å¼•æ•°ãªã—): ã‚ªãƒƒã‚ºå–å¾—ï¼‹ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼æ¤œçŸ¥")

    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚ªãƒƒã‚ºå–å¾— + ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼æ¤œçŸ¥
        print("\n[INFO] ã‚ªãƒƒã‚ºã‚’å–å¾—ä¸­...")
        odds_list = scraper.fetch_all_odds()

        if odds_list:
            scraper.save_odds_snapshot(odds_list)
            print(f"\nâœ… {len(odds_list)}ãƒ¬ãƒ¼ã‚¹ã®ã‚ªãƒƒã‚ºã‚’å–å¾—ã—ã¾ã—ãŸ")

            print("\n[INFO] ã‚¤ãƒ³ã‚µã‚¤ãƒ€ãƒ¼æ¤œçŸ¥ã‚’å®Ÿè¡Œä¸­...")
            detector.run_detection(odds_list)
        else:
            print("\n[WARN] ã‚ªãƒƒã‚ºã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

    print("\nâœ… å‡¦ç†å®Œäº†")


if __name__ == "__main__":
    main()
